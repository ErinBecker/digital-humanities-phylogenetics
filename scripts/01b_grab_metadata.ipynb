{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Metadata from `catalogue.json`\n",
    "\n",
    "The file `catalogue.json` contains all the catalog data for an [ORACC](http://oracc.org) project (for general information, see the [Oracc Open Data](http://oracc.org/doc/opendata) page). The file can be found at `http://oracc.org/[PROJECT]/catalogue.json`. In the URL replace [PROJECT] with your project or sub-project name (e.g. `dcclt` or `cams/gkab`).\n",
    "\n",
    "The file `catalogue.json` of each project is also included in the file `PROJECT.zip` in `http://oracc.org/PROJECT/json.zip`. \n",
    "\n",
    "The main item in a `catalogue.json` file is called `members`, which contains the information about all the items in the project catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Project\n",
    "Select the project or subproject of interest. Subprojects are indicated as `[PROJECT]/[SUBPROJECT]` or `[PROJECT]/[SUBPROJECT]/[SUBPROJECT]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project = input('Project or subproject abbreviation: ')\n",
    "project = project.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access File and Create Dataframe\n",
    "The `requests` library creates a Python `dictionary` out of a JSON file with the `.json()` function. The JSON catalogue file has all the P, Q, and X numbers of a project under the key `members`.\n",
    "\n",
    "The resulting dictionary `d` has the text ID numbers (P, Q, and X numbers) as keys, the value is another dictionary where each key is a field (`provenience`, `primary_publication`, etc) and the value is the content of that field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://oracc.org/' + project + '/catalogue.json'\n",
    "f = requests.get(url, timeout = 3)\n",
    "d = f.json()\n",
    "d = d['members']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe\n",
    "After the dictionary is transformed into a Pandas Dataframe, it needs to be transposed, so that the P, Q, and X numbers become indexes or row names (rather than column names), and each column represents a field in the catalog. \n",
    "\n",
    "Creating a Dataframe is not necessary, one may also manipulate the dictionary directly, but for demonstration purposes the Dataframe is a handy format. In manipulating the dictionary directly it is important to keep in mind that not all catalog fields have data for all entries, which means that not all dictionary keys are available for each P, Q, or X number.\n",
    "\n",
    "Example code for slicing the dictionary to select all entries that have `provenience = 'Ur'`:\n",
    "> `urcat = {key:value for key, value in d.items() if 'provenience' in d[key] and d[key]['provenience'] == 'Ur'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d).T.fillna('')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Relevant Fields\n",
    "First display all available fields, then select the ones that are relevant for the task at hand. The function `fillna('')` will put a blank (instead of `NaN`) in all fields that have no entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df[['designation', 'period', 'provenience',\n",
    "        'museum_no']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate\n",
    "The Dataframe may now be manipulated with standard Pandas methods. The example code selects the texts from Ur.\n",
    "> `ur = df1[df1.provenience == \"Ur\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save\n",
    "Save the resulting data set as a `csv` file. `UTF-8` encoding is the encoding with the widest support in text analysis (and also the encoding used by [ORACC](http://oracc.org). If you intend to use the catalog file in Excel, however, it is better to use `utf-16` encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = project.replace('/', '-') + '_cat.csv'\n",
    "with open('../data/metadata/' + filename, 'w') as w:\n",
    "    df1.to_csv(w, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
