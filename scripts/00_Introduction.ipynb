{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Old Babylonian Lists of Trees and Wooden Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction to research questions and analysis plan\n",
    "\n",
    "We are interested in understanding relationships among extant versions of lexical texts. Patterns in similarity of these texts may provide important information about text provenance and/or routes of influence from one geographical area onto another. \n",
    "\n",
    "We are also interested in understanding the patterns by which lexical texts evolved and changed. \n",
    "\n",
    "In comparing versions of a lexical text we may think of four types of features: \n",
    "\n",
    "1) presence or absence of entries  \n",
    "2) order of entries within a section  \n",
    "3) order of sections in a document  \n",
    "4) spelling of words  \n",
    "\n",
    "The following sections will explore these four features independently and in combination to uncover patterns of similarity among documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to dataset and data structure\n",
    "\n",
    "This notebook uses data from the Digital Corpus of Cuneiform Lexical Texts ([DCCLT](http://oracc.org/dcclt)) derived from parsed JSON files. For the JSON output from the Open Richly Annotated Cuneiform Corpus ([ORACC](http://oracc.org)) see the [ORACC Open Data documentation](http://oracc.museum.upenn.edu/doc/opendata/index.html).  \n",
    "\n",
    "The JSON files are parsed with the notebook [grab_json.ipynb](https://github.com/ErinBecker/digital-humanities-phylogenetics/blob/master/scripts/grab_json.ipynb). This notebook takes an input file, identifying the text IDs of the documents to be parsed. The input file is [ob_lists_wood.txt](https://github.com/ErinBecker/digital-humanities-phylogenetics/blob/master/data/text_ids/ob_lists_wood.txt). \n",
    "\n",
    "The input file lists all the Text IDs of Old Babylonian lists of trees and wooden objects currently in [DCCLT](http://oracc.org/dcclt), as well as the composite text of the [Nippur version](http://oracc.org/Q000039). Text IDs consist of a P plus a six-digit number (commonly referred to as P-number) that is recognized by [ORACC](http://oracc.org) and by the Cuneiform Digital Library Initiative ([CDLI](http://cdli.ucla.edu)) and that has become the de-facto standard in Assyriology. [CDLI](http://cdli.ucla.edu) provides metadata (provenience, period, publication, museum number, etc) for each text. Composite text IDs consist of a Q plus a six-digit number (for instance Q000039). Texts that have not (yet) been cataloged in [CDLI](http://cdli.ucla.edu) receive a (temporary) six-digit X number.\n",
    "\n",
    "The data are placed in the directory [data](https://github.com/ErinBecker/digital-humanities-phylogenetics/tree/master/data). The are comma-separated files have the following fields: \n",
    "\n",
    "| field         | description                     |\n",
    "|-----------\t|------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| id_line   \t| consists of a text ID (P, Q, or X number) plus a reference number \t|\n",
    "| label \t| line number: obverse/reverse, column number, line number (e.g. o ii 16')                                                          \t|\n",
    "| lemma      \t| Sumerian words in lemmatized form (e.g. lugal[king]N); for unlemmatized words the raw transliteration is taken                                                                                  \t|\n",
    "| base      \t| Sumerian words in original spelling, but without morphological prefixes or suffixes   |\n",
    "| extent | (for missing data): how many lines or columns (restricted vocabulary) are missing|\n",
    "| scope | (for missing data): what is missing - line, column, face, or surface (restricted vocabulary) |\n",
    "\n",
    "There are various types of missing data, represented in different ways. A word that is present, but not lemmatized is represented in its transliterated form, followed by [NA]NA (that is: Guideword and POS are both NA). Words that are partly or entirely illegible on the original document are by definition unlemmatized and are handled the same way.\n",
    "\n",
    "Lines or multiple lines that are missing are indicated in the fields `extent` and `scope`. `Extent` gives the number of missing lines (or missing columns, etc). The restricted vocabulary includes numbers and the words 'n' (unknown), 'beginning', and 'rest'. `Scope` indicates the scope of the missing text: line, column, obverse, etc.\n",
    "\n",
    "| type         | how represented                     |\n",
    "|-----------\t|------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| words with unknown lemmatization| siki-siki[NA]NA |\n",
    "| illegible words | x[NA]NA |\n",
    "| known number of missing lines \t|extent: '5' scope: 'line' |\n",
    "| unknown number of missing lines\t|extent: 'n' scope: 'line |\n",
    "| two missing columns  | extent: '2' scope: 'column'|\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
