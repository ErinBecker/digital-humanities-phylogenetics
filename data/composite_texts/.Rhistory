# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
df_composite$entry = gsub("(_.*\\])[a-zA-Z/]*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
df_composite$entry = gsub("\\]", "", df_composite$entry)
df_composite$entry = gsub("\\[", "", df_composite$entry)
df_composite$entry = gsub("\\{", "", df_composite$entry)
df_composite$entry = gsub("\\}", "", df_composite$entry)
df_composite$entry = gsub("_", "", df_composite$entry)
df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# cutoff is minimum length of kmer defining a real section
def_section_breaks = function(df_kmers, cutoff) {
df_kmers$section = NA
first_section_start = which(df_kmers$k >= cutoff)[1]
df_kmers$section[first_section_start] = TRUE
for(i in first_section_start:nrow(df_kmers)) {
if(df_kmers$k[i] >= cutoff) { df_kmers$section[i] = TRUE}
}
df_kmers
}
add_section_numbers = function(df_kmers) {
}
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#For plotting with words as labels (e.g. length of sections with section names)
#plot.new()
#plot.window(xlim=c(1,10), ylim=c(1,10))
#text(x = 1:5, y = 1:5, labels = stuff, cex = 0.5)
View(Q1)
View(Q1)
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
df_composite$entry = gsub("(_.*\\])[a-zA-Z/]*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
df_composite$entry = gsub("\\]", "", df_composite$entry)
df_composite$entry = gsub("\\[", "", df_composite$entry)
df_composite$entry = gsub("\\{", "", df_composite$entry)
df_composite$entry = gsub("\\}", "", df_composite$entry)
df_composite$entry = gsub("_", "", df_composite$entry)
df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# cutoff is minimum length of kmer defining a real section
def_section_breaks = function(df_kmers, cutoff) {
df_kmers$section = NA
first_section_start = which(df_kmers$k >= cutoff)[1]
df_kmers$section[first_section_start] = TRUE
for(i in first_section_start:nrow(df_kmers)) {
if(df_kmers$k[i] >= cutoff) { df_kmers$section[i] = TRUE}
else(df_kmers$section[i] = FALSE)
}
df_kmers
}
Q1 = def_section_breaks(Q1, 3)
View(Q1)
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
df_composite$entry = gsub("(_.*\\])[a-zA-Z/]*", "\\1", df_composite$entry) #for last word
#  # get rid of punctuation (but only {}[]_.)
# df_composite$entry = gsub("\\]", "", df_composite$entry)
# df_composite$entry = gsub("\\[", "", df_composite$entry)
# df_composite$entry = gsub("\\{", "", df_composite$entry)
# df_composite$entry = gsub("\\}", "", df_composite$entry)
# df_composite$entry = gsub("_", "", df_composite$entry)
# df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# cutoff is minimum length of kmer defining a real section
def_section_breaks = function(df_kmers, cutoff) {
df_kmers$section = NA
first_section_start = which(df_kmers$k >= cutoff)[1]
df_kmers$section[first_section_start] = TRUE
for(i in first_section_start:nrow(df_kmers)) {
if(df_kmers$k[i] >= cutoff) { df_kmers$section[i] = TRUE}
else(df_kmers$section[i] = FALSE)
}
df_kmers
}
Q1 = def_section_breaks(Q1, 3)
# add_section_numbers = function(df_kmers) {
#   df_kmers$sect_num = NA
#   counter = 1
#   for(i in nrow(df_kmers)) {
#     if(df_kmers$section[i] == FALSE) { counter = counter + 1 }
#
#   }
# }
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#For plotting with words as labels (e.g. length of sections with section names)
#plot.new()
#plot.window(xlim=c(1,10), ylim=c(1,10))
#text(x = 1:5, y = 1:5, labels = stuff, cex = 0.5)
View(Q1)
View(Q1)
test = Q1$line_a[1]
test
grepl("\\[[a-z]\\]", test)
grepl("\\[", test)
grep("\\[", test)
test = strsplit(test)
test = strsplit(test, "")
test
test = Q1$line_a[1]
test2 = strsplit(test, "[")
test2 = strsplit(test, "\\[")
test2
test3 = strsplit(test, "\\]")
test3
test3 = strsplit(test2, "\\]")
test2
test3 = strsplit(test2[[1]], "\\]")
test3
test
test2 = strsplit(test, "_")
test2
test2 = unlist(strsplit(test, "_"))
test2
gsub(".*\\[", "", test2)
line = gsub(".*\\[", "", test2)
line
line = gsub(".*\\]", "", test2)
line
line = Q1$line_a[1]
line
line = unlist(strsplit(line, "_"))
line
line = gsub(".*\\[", "", line)
line
line = gsub("\\]", "", line)
line
class(line)
