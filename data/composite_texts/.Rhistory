df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) Remove punctuation and set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#7) take out part of speech?
View(Q1)
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
library(stringr)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
# use ? for non-greedy matching
#  df_composite$entry = gsub("(\\]).*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
#  df_composite$entry = gsub("(_.*\\]).*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
#  df_composite$entry = gsub("\\]", "", df_composite$entry)
#  df_composite$entry = gsub("\\[", "", df_composite$entry)
#  df_composite$entry = gsub("\\{", "", df_composite$entry)
#  df_composite$entry = gsub("\\}", "", df_composite$entry)
#  df_composite$entry = gsub("_", "", df_composite$entry)
#  df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer2 = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer2)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer2
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) Remove punctuation and set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#7) take out part of speech?
View(Q1)
test = "udu[sheep]n_mu[sound]v/i_Å¡a[cvve]v/t"
test
gsub("(\\]).*_", paste0("\\1", "_"), test)
gsub("(\\]).*_?", paste0("\\1", "_"), test)
gsub("(\\]).*_{1}", paste0("\\1", "_"), test)
gsub("(\\])?.*_", paste0("\\1", "_"), test)
gsub("(\\]).*_", paste0("\\1", "_"), test)
test
gsub("(\\]).*_[^\\]]", paste0("\\1", "_"), test)
gsub("(\\])[::alphanum::]*_", paste0("\\1", "_"), test)
gsub("(\\])[::alphanum::/]*_", paste0("\\1", "_"), test)
gsub("(\\])[::alphanum::/]*_", paste0("\\1", "_"), test)
test2 = gsub("(\\]).*_", paste0("\\1", "_"), df_composite$entry)
test2 = gsub("(\\])[::alphanum::/]*_", paste0("\\1", "_"), test)
test2
test
test3 = gsub("(\\])[::alphanum::/]*_", paste0("\\1", "_"), test2)
test3
test2 = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), test)
test2
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
library(stringr)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
# use ? for non-greedy matching
#  df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
#  df_composite$entry = gsub("(_.*\\]).*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
#  df_composite$entry = gsub("\\]", "", df_composite$entry)
#  df_composite$entry = gsub("\\[", "", df_composite$entry)
#  df_composite$entry = gsub("\\{", "", df_composite$entry)
#  df_composite$entry = gsub("\\}", "", df_composite$entry)
#  df_composite$entry = gsub("_", "", df_composite$entry)
#  df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer2 = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer2)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer2
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) Remove punctuation and set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#7) take out part of speech?
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
library(stringr)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
# use ? for non-greedy matching
df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
#  df_composite$entry = gsub("(_.*\\]).*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
#  df_composite$entry = gsub("\\]", "", df_composite$entry)
#  df_composite$entry = gsub("\\[", "", df_composite$entry)
#  df_composite$entry = gsub("\\{", "", df_composite$entry)
#  df_composite$entry = gsub("\\}", "", df_composite$entry)
#  df_composite$entry = gsub("_", "", df_composite$entry)
#  df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer2 = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer2)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer2
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1_1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) Remove punctuation and set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#7) take out part of speech?
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
library(stringr)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
# use ? for non-greedy matching
df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
df_composite$entry = gsub("(_.*\\]).*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
#  df_composite$entry = gsub("\\]", "", df_composite$entry)
#  df_composite$entry = gsub("\\[", "", df_composite$entry)
#  df_composite$entry = gsub("\\{", "", df_composite$entry)
#  df_composite$entry = gsub("\\}", "", df_composite$entry)
#  df_composite$entry = gsub("_", "", df_composite$entry)
#  df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer2 = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer2)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer2
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1_2 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) Remove punctuation and set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#7) take out part of speech?
View(Q1)
View(Q1_2)
View(Q1_1)
View(Q1)
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
library(stringr)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
df_composite$entry = gsub("(_.*\\])[a-zA-Z/]*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
#  df_composite$entry = gsub("\\]", "", df_composite$entry)
#  df_composite$entry = gsub("\\[", "", df_composite$entry)
#  df_composite$entry = gsub("\\{", "", df_composite$entry)
#  df_composite$entry = gsub("\\}", "", df_composite$entry)
#  df_composite$entry = gsub("_", "", df_composite$entry)
#  df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer2 = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer2)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer2
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1_2 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) Remove punctuation and set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#7) take out part of speech?
View(Q1_2)
# Use getLongestCommonSubstring() from Rlibstree
# source("http://bioconductor.org/biocLite.R")
# biocLite("Rlibstree")
# Needs bioconductor and having difficulty installing on Jupyter notebook
# Want to test and make sure it works before I go through all the trouble
setwd("~/Box Sync/digital-humanities-phylogenetics/data/composite_texts/")
library(Rlibstree)
library(stringr)
## separate data from composites.csv into one csv for each composite text
# composites = read.csv(file = "composites.csv", stringsAsFactors = FALSE)
# composites$X = NULL
# composites$document = gsub("(.*)\\..*", "\\1", composites$id_line)
# composites$entry = composites$lemma
# composites$entry = gsub(" ", "_", composites$entry) #replace spaces with underscore
# unique_docs = unique(composites$document)
# sapply(unique_docs, function(x) {
#   lines = which(composites$document == x)
#   write.csv(composites[lines,], file = paste0(x, ".csv"), quote = FALSE, row.names = FALSE)
# })
create_kmers_df = function(file) {
df_composite = read.csv(file, stringsAsFactors = FALSE)
df_kmers = data.frame(line_a = character(nrow(df_composite)),
line_b = character(nrow(df_composite)),
kmer = character(nrow(df_composite)),
k = numeric(nrow(df_composite)),
stringsAsFactors=FALSE)
# get rid of part of speech (follows each ])
df_composite$entry = gsub("(\\])[a-zA-Z/]*_", paste0("\\1", "_"), df_composite$entry) #for all but last word
df_composite$entry = gsub("(_.*\\])[a-zA-Z/]*", "\\1", df_composite$entry) #for last word
# get rid of punctuation (but only {}[]_.)
df_composite$entry = gsub("\\]", "", df_composite$entry)
df_composite$entry = gsub("\\[", "", df_composite$entry)
df_composite$entry = gsub("\\{", "", df_composite$entry)
df_composite$entry = gsub("\\}", "", df_composite$entry)
df_composite$entry = gsub("_", "", df_composite$entry)
df_composite$entry = gsub("\\.", "", df_composite$entry)
for(i in 1:nrow(df_composite)-1) {
line_a = tolower(df_composite$entry[i])
line_b = tolower(df_composite$entry[i +1])
kmer = getLongestCommonSubstring(c(line_a, line_b))
kmer2 = gsub("[\x80-\xFF]", "", kmer)  # what other special characters?
k = nchar(kmer2)
df_kmers$line_a[i] = line_a
df_kmers$line_b[i] = line_b
df_kmers$kmer[i] = kmer2
df_kmers$k[i] = k
df_kmers
}
plot(df_kmers$k, type = "l")
plot(df_kmers$k, pch = ".")
df_kmers
}
Q1 = create_kmers_df("Q000001.csv")
# Q39 = create_kmers_df("Q000039.csv")
# Q40 = create_kmers_df("Q000040.csv")
# Q41 = create_kmers_df("Q000041.csv")
# Q42 = create_kmers_df("Q000042.csv")
# Things to check:
# 1) There are two lines in the composite text which represent
# missing lines. This seems strange to me.
# which(df_composite$entry == "")
# 2) getLongestCommonSubstring sticks a seemingly random additional
# character onto the end of the uncovered string.
# sometimes these characters are multibyte strings and can't be
# handled by nchar
# (mostly) Fixed this by gsubing out multibyte characters
# View(df_kmers[which(df_kmers$kmer != df_kmers$kmer2),])
#3) Even after fixing #2, kmer length is not reproducible
# running the code that creates df_kmers multiple times
# produces slight differences
# look into this
#4) Remove punctuation and set cutoff to 3 (anything below 3 is a section break)
#5) If entire guide word (between []) or the entire citation form (everything before [) matches, keep as part of section
#6) take out "nana" kmers
#7) take out part of speech?
View(Q1)
