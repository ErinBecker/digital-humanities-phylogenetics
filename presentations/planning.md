Analyses to do and/or clean up:
- Section definitions
  - Automated based on entry proximity. How does this influence later results? 
  - Test how well our analyses perform on other corpuses beyond Q39. 
  - Formal analysis of how the section definition performed across different Q texts.
  - Compare the results of the "entry proximity" vs "composite text" methods for defining sections.
- Order of entries within sections
  - apply synteny approach. Are there any changes in how this is implemented?
  - add "top" and "bottom" sections
 - Heatmaps for mapping sections across documents  
    - use as a way of describing the data. Section rarity, popularity. Size of sections, etc. 
~~ - Grouping documents by entry similarity (DTM)
    - Check results, clean up notebook  
    - Revisualize tree  
    - Add proveniance and period ~~
 - Checks of our methods:
    - Metadata (do docs from the same site/period co-branch)?
    - Making a artificial set of exemplars to test our methods on, for which similarity/relationship is known.
 - What is the effect of text length on methods? 
  
  
Benchmarks/Timeline:      
- Friday 11/3
  - Erin 
    - clean up the section presence/absence code, move to R markdown, and bookstrap
    - look into changing trees from cladograms to dendrograms
    - look into adding bootstrap support values to trees (from existing calculations)
  - Niek
    - look at existing trees for dtm analysis and make notes about relationships / interpretation
      

